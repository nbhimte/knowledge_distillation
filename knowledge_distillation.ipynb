{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbhimte/knowledge_distillation/blob/main/knowledge_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW5Jy95u0AKt"
      },
      "source": [
        "# Task-specific knowledge distillation for BERT using Hugging Face Transformers\n",
        "### Text Classification Example using `BERT-Base` as Teacher and `BERT-Tiny` as Student"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "188O9TLN0AKz"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO2k4dIk0AK0",
        "outputId": "c8489977-9098-4a34-d1f0-4318ec452af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "#%pip install \"pytorch==1.10.1\"\n",
        "%pip install transformers datasets tensorboard --upgrade\n",
        "\n",
        "!sudo apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbGA2Ve0AK2"
      },
      "source": [
        "This example will use the [Hugging Face Hub](https://huggingface.co/models) as remote model versioning service. To be able to push our model to the Hub, you need to register on the [Hugging Face](https://huggingface.co/join).\n",
        "If you already have an account you can skip this step.\n",
        "After you have an account, we will use the `notebook_login` util from the `huggingface_hub` package to log into our account and store our token (access key) on the disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "5a2006c756b0492bbe816d2b78054e8b",
            "ad21223359684093b8e4d634a44cf9ca",
            "58e25927fee74da1a0b2d0ad8ab5fa33",
            "bbb37547ff984a0f9117711dc0323c88",
            "464e2c2b94dd41e8a6c3df666aff1954",
            "9379a8036938495e9d9026a006b43a37",
            "28f66fb1f1f54e20a413e49971bff671",
            "b3d6bad7983e45069b1aa657b4fc4057",
            "c5b6d637b75d4152928fe05a5c7c3834",
            "92431ea7a2684ae0940c0fc3b7b16416",
            "bc59d921d044400db0f72f911b24cf88",
            "53f60cf5096147eaaba506530eb406c7",
            "e793d22b3826411e996aad7c1fcde15b",
            "45a895580e824af78613ca57c4b9d590",
            "e295ded6f75b40cc8f3c750ca850ea81",
            "29649febc1ce459085925d6d7ea85e99",
            "626714ee070e4ffba8d1f8b7175a9f56"
          ]
        },
        "id": "PXP4ZyY60AK2",
        "outputId": "69ff6d24-3a39-479f-b04b-5a7d40478271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "Cl7nzMGw9iIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqXztxeh0AK3"
      },
      "source": [
        "## Setup & Configuration\n",
        "\n",
        "In this step we will define global configurations and paramters, which are used across the whole end-to-end fine-tuning proccess, e.g. `teacher` and `studen` we will use.\n",
        "\n",
        "In this example, we will use [BERT-base](textattack/bert-base-uncased-SST-2) as Teacher and [BERT-Tiny](https://huggingface.co/google/bert_uncased_L-2_H-128_A-2) as Student. Our Teacher is already fine-tuned on our dataset, which makes it easy for us to directly start the distillation training job rather than fine-tuning the teacher first to then distill it afterwards.\n",
        "\n",
        "_**IMPORTANT**: This example will only work with a `Teacher` & `Student` combination where the Tokenizer is creating the same output._\n",
        "\n",
        "Additionally, describes the [FastFormers: Highly Efficient Transformer Models for Natural Language Understanding](https://arxiv.org/abs/2010.13382) paper an additional phenomenon.\n",
        "> In our experiments, we have observed that dis-\n",
        "tilled models do not work well when distilled to a\n",
        "different model type. Therefore, we restricted our\n",
        "setup to avoid distilling RoBERTa model to BERT\n",
        "or vice versa. The major difference between the\n",
        "two model groups is the input token (sub-word) em-\n",
        "bedding. We think that different input embedding\n",
        "spaces result in different output embedding spaces,\n",
        "and knowledge transfer with different spaces does\n",
        "not work well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKi2Zpfh0AK4"
      },
      "outputs": [],
      "source": [
        "# student_id = \"google/bert_uncased_L-2_H-128_A-2\"\n",
        "student_id = \"prajjwal1/bert-tiny-mnli\"\n",
        "# teacher_id = \"textattack/bert-base-uncased-SST-2\"\n",
        "teacher_id = \"ishan/bert-base-uncased-mnli\"\n",
        "\n",
        "# name for our repository on the hub\n",
        "repo_name = \"tiny-bert-mnli-distilled\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmbgpvv10AK4"
      },
      "source": [
        "Below are some checks to make sure the `Teacher` & `Student` are creating the same output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNMXoIgm0AK5",
        "outputId": "cfedd7d1-0679-42fd-c033-80b42665c1a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/3623493e7bb6187e46deb925ccff4e991d1f8192fedea8b7b7c6dba2df7b7654.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fdbb52f7ea7ed680e9048263ac6bfefa6b6c5f477560c5bc160ccdedcc03b326.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/0d4e9e253035c7ff672204ce5359060651302c4091cdfcd5425ac8535065b7be.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/119e82ef97fc6d4cb28627640419a6aad0b8253bbbb0c6e3f9140e5c8ff9bd14.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/d32a167178cbd8cc4764f8f348bee02e876e955e052058ab834b96e273997821.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/0eae28b82edb0850d17aaf1d3840b059817b307f1d04af6415fe44de8d31ca92.1788df22ba1a6817edb607a56efa931ee13ebad3b3500e58029a8f4e6d799a29\n",
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# init tokenizer\n",
        "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_id)\n",
        "\n",
        "# sample input\n",
        "sample = \"This is a basic example, with different words to test.\"\n",
        "\n",
        "# assert results\n",
        "assert teacher_tokenizer(sample) == student_tokenizer(sample), \"Tokenizers haven't created the same output\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEqsLRyu0AK5"
      },
      "source": [
        "## Dataset & Pre-processing\n",
        "\n",
        "As Dataset we will use the [Stanford Sentiment Treebank v2 (SST-2)](https://paperswithcode.com/dataset/sst) a text-classification for `sentiment-analysis`, which is included in the [GLUE benchmark](https://gluebenchmark.com/). The dataset is based on the dataset introduced by Pang and Lee (2005) and consists of 11,855 single sentences extracted from movie reviews. It was parsed with the Stanford parser and includes a total of 215,154 unique phrases from those parse trees, each annotated by 3 human judges. It uses the two-way (positive/negative) class split, with only sentence-level labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsnQO3k30AK6"
      },
      "outputs": [],
      "source": [
        "dataset_id=\"glue\"\n",
        "dataset_config=\"mnli\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz8Lxcnl0AK6"
      },
      "source": [
        "To load the `sst2` dataset, we use the `load_dataset()` method from the 🤗 Datasets library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "cda915085a1648d3b4f679855dd42438",
            "cd9dea15747a4f8a868656655b463129",
            "057bd76366764660ab4e21d4f007ff83",
            "1520853ce0504657bf10a06e67f1b954",
            "4f2df5a29124475086d98758531d623b",
            "58c5af5ae78649059c124da64764151a",
            "22149ff0b91143698135aa6b6f726a10",
            "0b14f86ea9fc4cc885bd158e4bded4c4",
            "f8529555971740718b6c519f9b7f0ed9",
            "ba46f457bbaa4a5e88386690fafb275e",
            "45b3bbec68854b2c9772d02e50cb3b10"
          ]
        },
        "id": "qSeHREA10AK7",
        "outputId": "51fd7a48-003e-4e8d-9743-93324f7f703f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cda915085a1648d3b4f679855dd42438"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 392702\n",
              "    })\n",
              "    validation_matched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9815\n",
              "    })\n",
              "    validation_mismatched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9832\n",
              "    })\n",
              "    test_matched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9796\n",
              "    })\n",
              "    test_mismatched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9847\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(dataset_id,dataset_config)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV4cEvl60AK7"
      },
      "source": [
        "### Pre-processing & Tokenization\n",
        "\n",
        "To distill our model we need to convert our \"Natural Language\" to token IDs. This is done by a 🤗 Transformers Tokenizer which will tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary). If you are not sure what this means check out [chapter 6](https://huggingface.co/course/chapter6/1?fw=tf) of the Hugging Face Course.\n",
        "\n",
        "We are going to use the tokenizer of the `Teacher`, but since both are creating same output you could also go with the `Student` tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs5-c0Fr0AK8",
        "outputId": "a390daec-760c-4352-d7e6-d4d00d81b8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/3623493e7bb6187e46deb925ccff4e991d1f8192fedea8b7b7c6dba2df7b7654.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fdbb52f7ea7ed680e9048263ac6bfefa6b6c5f477560c5bc160ccdedcc03b326.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/0d4e9e253035c7ff672204ce5359060651302c4091cdfcd5425ac8535065b7be.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(teacher_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjO8R4y40AK9"
      },
      "source": [
        "Additionally we add the `truncation=True` and `max_length=512` to align the length and truncate texts that are bigger than the maximum size allowed by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "9b96a36fd6f4481ba4bbfa8348886352",
            "8dd775ea21af46f4925690b4713b567e",
            "61c2c0d76a7547f292eea9bdc0abd798",
            "45d35bcd2eb44e4bb302678507eca7e0",
            "c3065e0761ff44468b5835ae42ce441d",
            "beb89bd9c60241fda18cc620d0a58127",
            "cf07b9e13a4a4797903a83dc84ef68a2",
            "0c555a6fe3944c0fbfad54b629d37ba9",
            "e0b273d972654565964c05004c95cda4",
            "996eab9a5c8246c081a12a5a4cc7ca02",
            "83e33d544ec643b9baa4c5d16c3f88bb"
          ]
        },
        "id": "VahutHos0AK9",
        "outputId": "5d3ac052-1f68-418b-ab88-7310e1f98b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9f857e39291dd5a1.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2799fafa20454de2.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b96a36fd6f4481ba4bbfa8348886352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-62444087ca2ad0a9.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-81278361b62030e8.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'hypothesis': Value(dtype='string', id=None),\n",
              " 'idx': Value(dtype='int32', id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'labels': ClassLabel(num_classes=3, names=['entailment', 'neutral', 'contradiction'], id=None),\n",
              " 'premise': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "def process(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"premise\"], truncation=True, max_length=512\n",
        "    )\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(process, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\",\"labels\")\n",
        "\n",
        "tokenized_datasets[\"test_matched\"].features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsBCXRor0AK-"
      },
      "source": [
        "## Distilling the model using `PyTorch` and `DistillationTrainer`\n",
        "\n",
        "\n",
        "Now that our `dataset` is processed, we can distill it. Normally, when fine-tuning a transformer model using PyTorch you should go with the `Trainer-API`. The [Trainer](https://huggingface.co/docs/transformers/v4.16.1/en/main_classes/trainer#transformers.Trainer) class provides an API for feature-complete training in PyTorch for most standard use cases.\n",
        "\n",
        "In our example we cannot use the `Trainer` out-of-the-box, since we need to pass in two models, the `Teacher` and the `Student` and compute the loss for both. But we can subclass the `Trainer` to create a `DistillationTrainer` which will take care of it and only overwrite the [compute_loss](https://github.com/huggingface/transformers/blob/c4ad38e5ac69e6d96116f39df789a2369dd33c21/src/transformers/trainer.py#L1962) method as well as the `init` method. In addition to this we also need to subclass the `TrainingArguments` to include the our distillation hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXymyHk30AK-"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "class DistillationTrainer(Trainer):\n",
        "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.teacher = teacher_model\n",
        "        # place teacher on same device as student\n",
        "        self._move_model_to_device(self.teacher,self.model.device)\n",
        "        self.teacher.eval()\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "\n",
        "        # compute student output\n",
        "        outputs_student = model(**inputs)\n",
        "\n",
        "        # compute teacher output\n",
        "        with torch.no_grad():\n",
        "          outputs_teacher = self.teacher(**inputs)\n",
        "\n",
        "        # assert size\n",
        "        assert outputs_student.logits.size() == outputs_teacher.logits.size()\n",
        "\n",
        "        # Soften probabilities and compute distillation loss\n",
        "        loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "        loss_logits = (loss_function(\n",
        "            F.log_softmax(outputs_student.logits / self.args.temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher.logits / self.args.temperature, dim=-1)) * (self.args.temperature ** 2))\n",
        "        # Return weighted student loss\n",
        "        student_loss=outputs_student.loss\n",
        "        loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "        return (loss, outputs_student) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR8baUwe0AK_"
      },
      "source": [
        "### Hyperparameter Definition, Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya2Hzf-w0ALA",
        "outputId": "1db31a1a-78d8-4c6d-fe0e-e60c6e308a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "loading configuration file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3ac9c4ab3837356d9fe68f684b16a9f7d02b288d0fb8a9e0ccae7fab09c9b016.cda3a9d6349a2be3b0c218d9a1414c149919b95733a609cd1e04f6ff0e0472e0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"ishan/bert-base-uncased-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"entailment\",\n",
            "    \"1\": \"neutral\",\n",
            "    \"2\": \"contradiction\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"contradiction\": \"2\",\n",
            "    \"entailment\": \"0\",\n",
            "    \"neutral\": \"1\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/ishan/bert-base-uncased-mnli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/14f90e14d7dd3cd6c5c140ec353540860fdb5c57016b0b9eb6d1051b8cb49e2d.45995793bf52b71150a425aea5e8543ee7d4b105c3e56df9c7be81d38fba2868\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ishan/bert-base-uncased-mnli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"entailment\",\n",
            "    \"1\": \"neutral\",\n",
            "    \"2\": \"contradiction\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"contradiction\": \"2\",\n",
            "    \"entailment\": \"0\",\n",
            "    \"neutral\": \"1\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/373c87d6d6dd4ba88996cc2eeb0aac8c1252c4c1a28b1c6d7d7d9eb0e8e22f39.ea3c41a2198cf30aeee9a72356f7a96092c222eb5ea851c34d29419deb2e76b3\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at prajjwal1/bert-tiny-mnli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from huggingface_hub import HfFolder\n",
        "\n",
        "# create label2id, id2label dicts for nice outputs for the model\n",
        "labels = tokenized_datasets[\"train\"].features[\"labels\"].names\n",
        "num_labels = len(labels)\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "\n",
        "# define training args\n",
        "training_args = DistillationTrainingArguments(\n",
        "    output_dir=repo_name,\n",
        "    num_train_epochs=4,\n",
        "    #128\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    fp16=True,\n",
        "    learning_rate=3e-4,\n",
        "    seed=33,\n",
        "    # logging & evaluation strategies\n",
        "    logging_dir=f\"{repo_name}/logs\",\n",
        "    logging_strategy=\"epoch\", # to get more information to TB\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"tensorboard\",\n",
        "    # push to hub parameters\n",
        "    push_to_hub=True,\n",
        "    hub_strategy=\"every_save\",\n",
        "    hub_model_id=repo_name,\n",
        "    hub_token=HfFolder.get_token(),\n",
        "    # distilation parameters\n",
        "    alpha=0.5,\n",
        "    temperature=4.0\n",
        "    )\n",
        "\n",
        "# define data_collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# define model\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    teacher_id,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# define student model\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    student_id,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XQc0snk0ALB"
      },
      "source": [
        "### Evaluation metric\n",
        "\n",
        "we can create a `compute_metrics` function to evaluate our model on the test set. This function will be used during the training process to compute the `accuracy` & `f1` of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdIZkhq60ALB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "# define metrics and metrics function\n",
        "accuracy_metric = load_metric( \"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    return {\n",
        "        \"accuracy\": acc[\"accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN7tlq7v0ALC"
      },
      "source": [
        "## Training\n",
        "\n",
        "Start training with calling `trainer.train`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config http.postBuffer 524288000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duf1mipL-Leu",
        "outputId": "93bb4a2f-2dae-496c-a479-b43097fb78ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not in a git directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVuIbq250ALC",
        "outputId": "8e62fe7c-a17a-4752-ca86-f75089b1dba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning https://huggingface.co/nbhimte/tiny-bert-mnli-distilled into local empty directory.\n",
            "Using amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer = DistillationTrainer(\n",
        "    student_model,\n",
        "    training_args,\n",
        "    teacher_model=teacher_model,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu86dfof0ALC"
      },
      "source": [
        "start training using the `DistillationTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8G2KQ4ww0ALD",
        "outputId": "49cf65ba-11db-41fc-80ee-4edb2823728b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 392702\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 196352\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='196352' max='196352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [196352/196352 1:57:04, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.743300</td>\n",
              "      <td>0.740455</td>\n",
              "      <td>0.328273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.728700</td>\n",
              "      <td>0.736857</td>\n",
              "      <td>0.328069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.720100</td>\n",
              "      <td>0.733062</td>\n",
              "      <td>0.326949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.712100</td>\n",
              "      <td>0.732788</td>\n",
              "      <td>0.328986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to tiny-bert-mnli-distilled/checkpoint-49088\n",
            "Configuration saved in tiny-bert-mnli-distilled/checkpoint-49088/config.json\n",
            "Model weights saved in tiny-bert-mnli-distilled/checkpoint-49088/pytorch_model.bin\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/checkpoint-49088/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/checkpoint-49088/special_tokens_map.json\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to tiny-bert-mnli-distilled/checkpoint-98176\n",
            "Configuration saved in tiny-bert-mnli-distilled/checkpoint-98176/config.json\n",
            "Model weights saved in tiny-bert-mnli-distilled/checkpoint-98176/pytorch_model.bin\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/checkpoint-98176/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/checkpoint-98176/special_tokens_map.json\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to tiny-bert-mnli-distilled/checkpoint-147264\n",
            "Configuration saved in tiny-bert-mnli-distilled/checkpoint-147264/config.json\n",
            "Model weights saved in tiny-bert-mnli-distilled/checkpoint-147264/pytorch_model.bin\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/checkpoint-147264/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/checkpoint-147264/special_tokens_map.json\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "Deleting older checkpoint [tiny-bert-mnli-distilled/checkpoint-98176] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to tiny-bert-mnli-distilled/checkpoint-196352\n",
            "Configuration saved in tiny-bert-mnli-distilled/checkpoint-196352/config.json\n",
            "Model weights saved in tiny-bert-mnli-distilled/checkpoint-196352/pytorch_model.bin\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/checkpoint-196352/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/checkpoint-196352/special_tokens_map.json\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/special_tokens_map.json\n",
            "Deleting older checkpoint [tiny-bert-mnli-distilled/checkpoint-49088] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from tiny-bert-mnli-distilled/checkpoint-196352 (score: 0.3289862455425369).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=196352, training_loss=0.7260512808311095, metrics={'train_runtime': 7024.1467, 'train_samples_per_second': 223.63, 'train_steps_per_second': 27.954, 'total_flos': 210715752136032.0, 'train_loss': 0.7260512808311095, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2unavjWF0ALD"
      },
      "source": [
        "## Hyperparameter Search for Distillation parameter `alpha` & `temperature` with optuna\n",
        "\n",
        "The parameter `alpha` & `temparature` in the `DistillationTrainer` can also be used when doing Hyperparamter search to maxizime our \"knowledge extraction\". As Hyperparamter Optimization framework are we using [Optuna](https://optuna.org/), which has a integration into the `Trainer-API`. Since we the `DistillationTrainer` is a sublcass of the `Trainer` we can use the `hyperparameter_search` without any code changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vND0ESYL0ALD",
        "outputId": "7b4535dc-1c76-4b0c-c2c9-d15cbe2debf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.6.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 53.1 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=0aa9090a08481a18cea6ee7455e373eac4a2434c62694547b8f1c420f6de8959\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOGnBz1Y0ALE"
      },
      "source": [
        "To do Hyperparameter Optimization using `optuna` we need to define our hyperparameter space. In this example we are trying to optimize/maximize the `num_train_epochs`, `learning_rate`, `alpha` & `temperature` for our `student_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ljv_paA0ALE"
      },
      "outputs": [],
      "source": [
        "def hp_space(trial):\n",
        "    return {\n",
        "      \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 10),\n",
        "      \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3 ,log=True),\n",
        "      \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
        "      \"temperature\": trial.suggest_int(\"temperature\", 2, 30),\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhITzeRM0ALF"
      },
      "source": [
        "To start our Hyperparmeter search we just need to call `hyperparameter_search` provide our `hp_space` and number of trials to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eib-5CiN0ALG",
        "outputId": "1347f1c1-078a-4bf3-dde8-9ecb961c09a3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"entailment\",\n",
            "    \"1\": \"neutral\",\n",
            "    \"2\": \"contradiction\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"contradiction\": \"2\",\n",
            "    \"entailment\": \"0\",\n",
            "    \"neutral\": \"1\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/373c87d6d6dd4ba88996cc2eeb0aac8c1252c4c1a28b1c6d7d7d9eb0e8e22f39.ea3c41a2198cf30aeee9a72356f7a96092c222eb5ea851c34d29419deb2e76b3\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at prajjwal1/bert-tiny-mnli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "/content/tiny-bert-mnli-distilled is already a clone of https://huggingface.co/nbhimte/tiny-bert-mnli-distilled. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "\u001b[32m[I 2022-04-17 05:38:16,728]\u001b[0m A new study created in memory with name: no-name-997d91bb-0c48-4181-bd14-f3c7e7796bbb\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"entailment\",\n",
            "    \"1\": \"neutral\",\n",
            "    \"2\": \"contradiction\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"contradiction\": \"2\",\n",
            "    \"entailment\": \"0\",\n",
            "    \"neutral\": \"1\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/373c87d6d6dd4ba88996cc2eeb0aac8c1252c4c1a28b1c6d7d7d9eb0e8e22f39.ea3c41a2198cf30aeee9a72356f7a96092c222eb5ea851c34d29419deb2e76b3\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at prajjwal1/bert-tiny-mnli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 392702\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 98176\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39206' max='98176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39206/98176 23:39 < 35:35, 27.61 it/s, Epoch 0.80/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='98176' max='98176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [98176/98176 59:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.458900</td>\n",
              "      <td>0.448937</td>\n",
              "      <td>0.329088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.432400</td>\n",
              "      <td>0.444797</td>\n",
              "      <td>0.328884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to tiny-bert-mnli-distilled/run-0/checkpoint-49088\n",
            "Configuration saved in tiny-bert-mnli-distilled/run-0/checkpoint-49088/config.json\n",
            "Model weights saved in tiny-bert-mnli-distilled/run-0/checkpoint-49088/pytorch_model.bin\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/run-0/checkpoint-49088/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/run-0/checkpoint-49088/special_tokens_map.json\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to tiny-bert-mnli-distilled/run-0/checkpoint-98176\n",
            "Configuration saved in tiny-bert-mnli-distilled/run-0/checkpoint-98176/config.json\n",
            "Model weights saved in tiny-bert-mnli-distilled/run-0/checkpoint-98176/pytorch_model.bin\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/run-0/checkpoint-98176/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/run-0/checkpoint-98176/special_tokens_map.json\n",
            "tokenizer config file saved in tiny-bert-mnli-distilled/tokenizer_config.json\n",
            "Special tokens file saved in tiny-bert-mnli-distilled/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from tiny-bert-mnli-distilled/run-0/checkpoint-49088 (score: 0.32908813041263374).\n",
            "\u001b[32m[I 2022-04-17 06:37:22,946]\u001b[0m Trial 0 finished with value: 0.32888436067244015 and parameters: {'num_train_epochs': 2, 'learning_rate': 2.114833210641637e-05, 'alpha': 0.21060690594290088, 'temperature': 5}. Best is trial 0 with value: 0.32888436067244015.\u001b[0m\n",
            "Trial:\n",
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6541d21313d66b47824c6d9dfe8500c425923193e04bb3f5421e9609a29e8ae7.77cb6cfe5ec6550086efef613e1c1be70610fcaaf9fc90c978e1b179b628eb46\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"mnli\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"entailment\",\n",
            "    \"1\": \"neutral\",\n",
            "    \"2\": \"contradiction\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"contradiction\": \"2\",\n",
            "    \"entailment\": \"0\",\n",
            "    \"neutral\": \"1\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny-mnli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/373c87d6d6dd4ba88996cc2eeb0aac8c1252c4c1a28b1c6d7d7d9eb0e8e22f39.ea3c41a2198cf30aeee9a72356f7a96092c222eb5ea851c34d29419deb2e76b3\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at prajjwal1/bert-tiny-mnli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise. If hypothesis, idx, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 392702\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 147264\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27632' max='147264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 27632/147264 16:41 < 1:12:16, 27.59 it/s, Epoch 0.56/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def student_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        student_id,\n",
        "        num_labels=num_labels,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "trainer = DistillationTrainer(\n",
        "    model_init=student_init,\n",
        "    args=training_args,\n",
        "    teacher_model=teacher_model,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    n_trials=50,\n",
        "    direction=\"maximize\",\n",
        "    hp_space=hp_space\n",
        ")\n",
        "\n",
        "print(best_run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byaCA1BE0ALH"
      },
      "source": [
        "Since optuna is just finding the best hyperparameters we need to fine-tune our model again using the best hyperparamters from the `best_run`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN1-_Q-j0ALI"
      },
      "outputs": [],
      "source": [
        "# overwrite initial hyperparameters with from the best_run\n",
        "for k,v in best_run.hyperparameters.items():\n",
        "    setattr(training_args, k, v)\n",
        "\n",
        "# Define a new repository to store our distilled model\n",
        "best_model_ckpt = \"tiny-bert-best\"\n",
        "training_args.output_dir = best_model_ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD5ES_Uc0ALJ"
      },
      "source": [
        "We have overwritten the default Hyperparameters with the one from our `best_run` and can start the training now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXkk0FhM0ALJ"
      },
      "outputs": [],
      "source": [
        "# Create a new Trainer with optimal parameters\n",
        "optimal_trainer = DistillationTrainer(\n",
        "    student_model,\n",
        "    training_args,\n",
        "    teacher_model=teacher_model,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "optimal_trainer.train()\n",
        "\n",
        "\n",
        "# save best model, metrics and create model card\n",
        "trainer.create_model_card(model_name=training_args.hub_model_id)\n",
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoF5MfOM0ALJ"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "whoami = HfApi().whoami()\n",
        "username = whoami['name']\n",
        "\n",
        "print(f\"https://huggingface.co/{username}/{repo_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE7wpJzn0ALK"
      },
      "source": [
        "## Results\n",
        "\n",
        "We were able to achieve a `accuracy` of 0.8337, which is a very good result for our model. Our distilled `Tiny-Bert` has 96% less parameters than the teacher `bert-base` and runs ~46.5x faster while preserving over 90% of BERT’s performances as measured on the SST2 dataset.\n",
        "\n",
        "| model | Parameter | Speed-up | Accuracy |\n",
        "|------------|-----------|----------|----------|\n",
        "| BERT-base  | 109M      | 1x       | 93%      |\n",
        "| tiny-BERT  | 4M        | 46.5x    | 83%      |\n",
        "\n",
        "_Note: The [FastFormers paper](https://arxiv.org/abs/2010.13382) uncovered that the biggest boost in performance is observerd when having 6 or more layers in the student. The [google/bert_uncased_L-2_H-128_A-2](https://huggingface.co/google/bert_uncased_L-2_H-128_A-2) we used only had 2, which means when changing our student to, e.g. `distilbert-base-uncased` we should better performance in terms of accuracy._\n",
        "\n",
        "If you are now planning to implement and add task-specific knowledge distillation to your models. I suggest to take a look at the [sagemaker-distillation](https://github.com/philschmid/knowledge-distillation-transformers-pytorch-sagemaker/blob/master/sagemaker-distillation.ipynb), which shows how to run task-specific knowledge distillation on Amazon SageMaker. For the example i created a script deriving this notebook to make it as easy as possible to use for you. You only need to define your `teacher_id`, `student_id` as well as your `dataset` config to run task-specific knowledge distillation for `text-classification`.\n",
        "\n",
        "```python\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "\n",
        "# hyperparameters, which are passed into the training job\n",
        "hyperparameters={\n",
        "    'teacher_id':'textattack/bert-base-uncased-SST-2',\n",
        "    'student_id':'google/bert_uncased_L-2_H-128_A-2',\n",
        "    'dataset_id':'glue',\n",
        "    'dataset_config':'sst2',\n",
        "    # distillation parameter\n",
        "    'alpha': 0.5,\n",
        "    'temparature': 4,\n",
        "    # hpo parameter\n",
        "    \"run_hpo\": True,\n",
        "    \"n_trials\": 100,\n",
        "}\n",
        "\n",
        "# create the Estimator\n",
        "huggingface_estimator = HuggingFace(..., hyperparameters=hyperparameters)\n",
        "\n",
        "# start knwonledge distillation training\n",
        "huggingface_estimator.fit()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JUrlC7p0ALL"
      },
      "source": []
    }
  ],
  "metadata": {
    "instance_type": "ml.t3.medium",
    "interpreter": {
      "hash": "ec1370a512a4612a2908be3c3c8b0de1730d00dc30104daff827065aeaf438b7"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a2006c756b0492bbe816d2b78054e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad21223359684093b8e4d634a44cf9ca",
              "IPY_MODEL_58e25927fee74da1a0b2d0ad8ab5fa33",
              "IPY_MODEL_bbb37547ff984a0f9117711dc0323c88",
              "IPY_MODEL_464e2c2b94dd41e8a6c3df666aff1954",
              "IPY_MODEL_9379a8036938495e9d9026a006b43a37"
            ],
            "layout": "IPY_MODEL_28f66fb1f1f54e20a413e49971bff671"
          }
        },
        "ad21223359684093b8e4d634a44cf9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d6bad7983e45069b1aa657b4fc4057",
            "placeholder": "​",
            "style": "IPY_MODEL_c5b6d637b75d4152928fe05a5c7c3834",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "58e25927fee74da1a0b2d0ad8ab5fa33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_92431ea7a2684ae0940c0fc3b7b16416",
            "placeholder": "​",
            "style": "IPY_MODEL_bc59d921d044400db0f72f911b24cf88",
            "value": ""
          }
        },
        "bbb37547ff984a0f9117711dc0323c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_53f60cf5096147eaaba506530eb406c7",
            "style": "IPY_MODEL_e793d22b3826411e996aad7c1fcde15b",
            "tooltip": ""
          }
        },
        "464e2c2b94dd41e8a6c3df666aff1954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a895580e824af78613ca57c4b9d590",
            "placeholder": "​",
            "style": "IPY_MODEL_e295ded6f75b40cc8f3c750ca850ea81",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "9379a8036938495e9d9026a006b43a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_29649febc1ce459085925d6d7ea85e99",
            "style": "IPY_MODEL_626714ee070e4ffba8d1f8b7175a9f56",
            "tooltip": ""
          }
        },
        "28f66fb1f1f54e20a413e49971bff671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b3d6bad7983e45069b1aa657b4fc4057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b6d637b75d4152928fe05a5c7c3834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92431ea7a2684ae0940c0fc3b7b16416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc59d921d044400db0f72f911b24cf88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f60cf5096147eaaba506530eb406c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e793d22b3826411e996aad7c1fcde15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "45a895580e824af78613ca57c4b9d590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e295ded6f75b40cc8f3c750ca850ea81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29649febc1ce459085925d6d7ea85e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "626714ee070e4ffba8d1f8b7175a9f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "cda915085a1648d3b4f679855dd42438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd9dea15747a4f8a868656655b463129",
              "IPY_MODEL_057bd76366764660ab4e21d4f007ff83",
              "IPY_MODEL_1520853ce0504657bf10a06e67f1b954"
            ],
            "layout": "IPY_MODEL_4f2df5a29124475086d98758531d623b"
          }
        },
        "cd9dea15747a4f8a868656655b463129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58c5af5ae78649059c124da64764151a",
            "placeholder": "​",
            "style": "IPY_MODEL_22149ff0b91143698135aa6b6f726a10",
            "value": "100%"
          }
        },
        "057bd76366764660ab4e21d4f007ff83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b14f86ea9fc4cc885bd158e4bded4c4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8529555971740718b6c519f9b7f0ed9",
            "value": 5
          }
        },
        "1520853ce0504657bf10a06e67f1b954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba46f457bbaa4a5e88386690fafb275e",
            "placeholder": "​",
            "style": "IPY_MODEL_45b3bbec68854b2c9772d02e50cb3b10",
            "value": " 5/5 [00:00&lt;00:00, 74.35it/s]"
          }
        },
        "4f2df5a29124475086d98758531d623b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c5af5ae78649059c124da64764151a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22149ff0b91143698135aa6b6f726a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b14f86ea9fc4cc885bd158e4bded4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8529555971740718b6c519f9b7f0ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba46f457bbaa4a5e88386690fafb275e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b3bbec68854b2c9772d02e50cb3b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b96a36fd6f4481ba4bbfa8348886352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dd775ea21af46f4925690b4713b567e",
              "IPY_MODEL_61c2c0d76a7547f292eea9bdc0abd798",
              "IPY_MODEL_45d35bcd2eb44e4bb302678507eca7e0"
            ],
            "layout": "IPY_MODEL_c3065e0761ff44468b5835ae42ce441d"
          }
        },
        "8dd775ea21af46f4925690b4713b567e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb89bd9c60241fda18cc620d0a58127",
            "placeholder": "​",
            "style": "IPY_MODEL_cf07b9e13a4a4797903a83dc84ef68a2",
            "value": "100%"
          }
        },
        "61c2c0d76a7547f292eea9bdc0abd798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c555a6fe3944c0fbfad54b629d37ba9",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0b273d972654565964c05004c95cda4",
            "value": 10
          }
        },
        "45d35bcd2eb44e4bb302678507eca7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996eab9a5c8246c081a12a5a4cc7ca02",
            "placeholder": "​",
            "style": "IPY_MODEL_83e33d544ec643b9baa4c5d16c3f88bb",
            "value": " 10/10 [00:00&lt;00:00, 11.12ba/s]"
          }
        },
        "c3065e0761ff44468b5835ae42ce441d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb89bd9c60241fda18cc620d0a58127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf07b9e13a4a4797903a83dc84ef68a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c555a6fe3944c0fbfad54b629d37ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b273d972654565964c05004c95cda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "996eab9a5c8246c081a12a5a4cc7ca02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e33d544ec643b9baa4c5d16c3f88bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}